{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gtfParser Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#######################################################################################\n",
    "###                                                                                 ###\n",
    "###     Copyright (C) 2019  Zhongxu ZHU, CityU, 20200925                            ###\n",
    "#######################################################################################\n",
    "\n",
    "# https://github.com/Jverma/GFF-Parser\n",
    "\n",
    "\n",
    "\n",
    "class gtfParser:\n",
    "    def __init__(self, input_file):\n",
    "        import sys\n",
    "        self.data = {}\n",
    "        self.dict = {}\n",
    "        self.gene_attributes_dict = {} # ZZX\n",
    "        self.transcriptID_geneID_dict = {} # ZZX\n",
    "\n",
    "        sys.stderr.write(\"#####################\\nParsing reference gtf file: \" + input_file + '\\n#####################\\n')\n",
    "\n",
    "        for line in open(input_file):\n",
    "            if line.startswith(\"#\"): continue\n",
    "            record = line.strip().split(\"\\t\")\n",
    "            sequence_name = record[0]\n",
    "            source = record[1]\n",
    "            feature = record[2]\n",
    "            start = int(record[3])\n",
    "            end = int(record[4])\n",
    "            if (record[5] != '.'):\n",
    "                score = record[5]\n",
    "            else:\n",
    "                score = None\n",
    "            strand = record[6]\n",
    "            if (record[7] != '.'):\n",
    "                frame = record[7]\n",
    "            else:\n",
    "                frame = None\n",
    "            attributes = record[8].split(';')\n",
    "            attributes = [x.strip() for x in attributes[0:-1]] # ZZX\n",
    "            attributes = {x.split(' ')[0]: x.split(' ')[1].strip(\"\\\"\") for x in attributes if \" \" in x} # ZZX\n",
    "\n",
    "            if not (sequence_name in self.data): self.data[sequence_name] = []\n",
    "            alpha = {'source': source, 'feature': feature, 'start': start, 'end': end, 'score': score, 'strand': strand,\n",
    "                     'frame': frame}\n",
    "            # python 3 .items(), python 2 .iteritems() ZZX\n",
    "            for k, v in attributes.items(): alpha[k] = v\n",
    "            self.data[sequence_name].append(alpha)\n",
    "\n",
    "        # ZZX\n",
    "        for k, v in self.data.items():\n",
    "            for alpha in v:\n",
    "                gene_id = alpha[\"gene_id\"]\n",
    "                transcript_id = alpha[\"transcript_id\"]\n",
    "\n",
    "                self.transcriptID_geneID_dict[transcript_id] = gene_id\n",
    "                if gene_id in self.gene_attributes_dict.keys():\n",
    "                    self.gene_attributes_dict[gene_id].append(alpha)\n",
    "                else:\n",
    "                    self.gene_attributes_dict[gene_id] = list()\n",
    "                    self.gene_attributes_dict[gene_id].append(alpha)\n",
    "\n",
    "\n",
    "    def getRecordsByID(self, id, attType, attValue):\n",
    "        \"\"\" Gets all the features for a given gene.\n",
    "            Parameters\n",
    "            ----------\n",
    "            id : Identifier of the gene (gene_id) or mRNA (transcript_id).\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            A list of dictionaries where each dictionary contains the\n",
    "            informations about features for the transcript.\n",
    "            \"\"\"\n",
    "\n",
    "        att_list = []\n",
    "        if id in self.gene_attributes_dict.keys():\n",
    "            for x in self.gene_attributes_dict[id]:\n",
    "                if ( attType in x.keys() and  x[attType] == attValue ):\n",
    "                    att_info = x\n",
    "                    att_list.append(att_info)\n",
    "        elif id in self.transcriptID_geneID_dict.keys():\n",
    "            for x in self.gene_attributes_dict[self.transcriptID_geneID_dict[id]]:\n",
    "                if ( attType in x.keys() and  x[attType] == attValue and x[\"transcript_id\"] == id):\n",
    "                    att_info = x\n",
    "                    att_list.append(att_info)\n",
    "        else:\n",
    "            sys.stderr.write(\"Could not find ID \"+id+'\\n')\n",
    "            sys.exit(1)\n",
    "\n",
    "        return att_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "import fastaparser\n",
    "\n",
    "\"\"\"\n",
    "Description\n",
    "\"\"\"\n",
    "__author__    = \"Zhongxu\"\n",
    "__copyright__ = \"Copyright 2020, Planet Earth\"\n",
    "\n",
    "sys.argv = [\"\", \"-c\", \"/data/home2/Zhongxu/tmp/ORFFinder/HCC-Organoid/candidate.aa.fa\",\n",
    "                \"-r\", \"/data/home2/Zhongxu/tmp/ORFFinder/HCC-Organoid/ref.aa.fa\",\n",
    "                \"-m\", \"/data/home2/Zhongxu/tmp/ORFFinder/HCC-Organoid/transcript.gene.map\",\n",
    "                \"-o\", \"/data/home2/Zhongxu/tmp/ORFFinder/HCC-Organoid/orf.analysis.tsv\",\n",
    "                \"-g\", \"/data/home2/Zhongxu/Ref/refSeq.hg38.gtf\",\n",
    "                #\"-g\", \"/data/home2/Zhongxu/ref/refSeq.hg19.gtf\",\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/cuhk-crc/analysis/t.gtf\"\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/pbFLNC/c99i95refMin2/gff/s2.clean.gtf\"\n",
    "                \"-s\", \"/dataserver145/genomics/zhongxu/work/HCC-organoid-AS/analysis/02gff/02organoid/1prepareMergedGff/all.5.filter.gtf\"\n",
    "            ]\n",
    "\n",
    "parser = OptionParser()\n",
    "parser.add_option(\"-c\", \"--candidate\", dest=\"candidate\",\n",
    "                  help=\"candidate protein sequence predicted by ORFFinder\", metavar=\"FILE\")\n",
    "parser.add_option(\"-r\", \"--reference\", dest=\"reference\",\n",
    "                  help=\"reference protein sequence\", metavar=\"FILE\")\n",
    "parser.add_option(\"-m\", \"--map\", dest=\"idmap\",\n",
    "                  help=\"1st col: transcript ID, 2ed col: Gene ID\", metavar=\"FILE\")\n",
    "parser.add_option(\"-o\", \"--output\", dest=\"out\",\n",
    "                  help=\"Output file path\", metavar=\"FILE\")\n",
    "parser.add_option(\"-g\", \"--refgtf\", dest=\"refgtf\",\n",
    "                  help=\"GTF file path\", metavar=\"FILE\")\n",
    "parser.add_option(\"-s\", \"--usergtf\", dest=\"usergtf\",\n",
    "                  help=\"GTF file path\", metavar=\"FILE\")\n",
    "parser.add_option(\"-b\", \"--blast\", dest=\"blast\",\n",
    "                  help=\"Blast file path\", metavar=\"FILE\")\n",
    "#-----------------------------------------------------\n",
    "\n",
    "\n",
    "def proteinSimilarity(seq1,seq2):\n",
    "    from Bio import pairwise2 as pw2\n",
    "    seq_length = min(len(seq1), len(seq2))\n",
    "    global_align = pw2.align.globalxx(seq1, seq2)\n",
    "    matches = global_align[0][2]\n",
    "    percent_match = (matches / seq_length) * 100\n",
    "    seq2_res = global_align[0][0] + '\\n' + global_align[0][1]\n",
    "    return round( percent_match,1 ), seq2_res\n",
    "\n",
    "#-----------------------------------------------------\n",
    "(options, args) = parser.parse_args()\n",
    "#-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/home2/Zhongxu/tmp/ORFFinder/HCC-Organoid/transcript.gene.map' mode='r' encoding='UTF-8'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "__main__:7: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/home2/Zhongxu/tmp/ORFFinder/HCC-Organoid/transcript.gene.map' mode='r' encoding='UTF-8'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "#####################\n",
      "Parsing reference gtf file: /data/home2/Zhongxu/Ref/refSeq.hg38.gtf\n",
      "#####################\n",
      "__main__:22: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/home2/Zhongxu/Ref/refSeq.hg38.gtf' mode='r' encoding='UTF-8'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# parsing this file to store gene and transcript mapping information\n",
    "transcriptGeneMap = {line.strip().split(\"\\t\")[0]:line.strip().split(\"\\t\")[1] for line in open(options.idmap)}\n",
    "geneTranscriptListMap = {}\n",
    "\n",
    "for line in open(options.idmap):\n",
    "    gene = line.strip().split(\"\\t\")[1]\n",
    "    transcript = line.strip().split(\"\\t\")[0]\n",
    "    if not gene in geneTranscriptListMap.keys():\n",
    "        geneTranscriptListMap[gene]=[]\n",
    "    geneTranscriptListMap[gene].append(transcript)\n",
    "        \n",
    "\n",
    "\n",
    "# store CDS start and end position\n",
    "refCDSStartEndMap = {}\n",
    "ref_seq_gtf = gtfParser(options.refgtf)\n",
    "\n",
    "# parsing ref protein sequence and store cds start and end\n",
    "refIdSeqMap = {}\n",
    "\n",
    "with open(options.reference) as fasta_file:\n",
    "    parser = fastaparser.Reader(fasta_file)\n",
    "    for seq in parser:\n",
    "        if seq.sequence_as_string() == \"SEQUENCE UNAVAILABLE\": continue\n",
    "        for e in seq.id.split(\";\"):\n",
    "            # obtain cds start and end\n",
    "            refmRNA_start = ref_seq_gtf.getRecordsByID(e, \"feature\", \"start_codon\")\n",
    "            start = ''\n",
    "            end = ''\n",
    "                        \n",
    "            if len(refmRNA_start) != 1:\n",
    "                start = ''\n",
    "                end = ''\n",
    "            else:\n",
    "                strand = refmRNA_start[0][\"strand\"]\n",
    "                if strand == '+':                \n",
    "                    start = refmRNA_start[0][\"start\"]\n",
    "                else: # 如果在负链\n",
    "                    start = refmRNA_start[0][\"end\"]\n",
    "                \n",
    "                refmRNA_end = ref_seq_gtf.getRecordsByID(e, \"feature\", \"stop_codon\")\n",
    "                if (len(refmRNA_end) != 1):\n",
    "                    end = ''\n",
    "                else:\n",
    "                    if strand == '+':\n",
    "                        end = refmRNA_end[0][\"end\"]\n",
    "                    else:\n",
    "                        end = refmRNA_end[0][\"start\"]           \n",
    "            \n",
    "            refCDSStartEndMap[e] = str(start)+\"|\"+str(end)\n",
    "            # remove * at the end of sequence and remove the first M amino acid\n",
    "            refIdSeqMap[e] = seq.sequence_as_string()[1:-1]     \n",
    "del ref_seq_gtf\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------\n",
    "# 将blast的结果读到map中，ORFID：line #结果是best的，一个orf只对应一行\n",
    "\n",
    "# parsing ref protein sequence and store cds start and end\n",
    "user_seq_gtf = gtfParser(options.usergtf)\n",
    "userCDSStartEndMap = {}\n",
    "\n",
    "# parsing predicted ORF and store cds start and end\n",
    "canIdSeqMap = {}\n",
    "def mapTranscriptPosToGenomic(gtf, transcriptID, start, end):\n",
    "    records = gtf.getRecordsByID(transcriptID, \"feature\", \"exon\")\n",
    "    strand = records[0][\"strand\"]\n",
    "    \n",
    "    regions = []\n",
    "    \n",
    "    for record in records:\n",
    "        e_start = record[\"start\"]\n",
    "        e_end   = record[\"end\"]\n",
    "        regions.extend(list(range(e_start,e_end+1)))\n",
    "    \n",
    "    if strand == '+':\n",
    "        start = regions[int(start)] # 本来打算要start-1的，不知道为什么不减1得到的是正确的\n",
    "        end   = regions[int(end)]\n",
    "    else:\n",
    "        start = regions[-1*int(start)-1] # 本来打算start，不知道为什么必须减1得到的是正确的\n",
    "        end   = regions[-1*int(end)-1]\n",
    "    return start, end\n",
    "\n",
    "\n",
    "with open(options.candidate) as fasta_file:\n",
    "    parser = fastaparser.Reader(fasta_file)\n",
    "\n",
    "    for seq in parser:\n",
    "        \n",
    "        id = seq.id.split(\"_\",1)[1].split(\":\")[0]\n",
    "        start = seq.id.split(\":\")[1]\n",
    "        end = seq.id.split(\":\")[2].split(\" \")[0]\n",
    "        orf = id+\":\"+start+\":\"+end\n",
    "        \n",
    "        if id in canIdSeqMap.keys(): # 选择最长的那个\n",
    "            if ( (len(seq.sequence_as_string()) -1 ) > len(canIdSeqMap[id]) ): # 减1是不考虑第一个M氨基酸\n",
    "                canIdSeqMap[id] = seq.sequence_as_string()[1:]\n",
    "                g_start, g_end = mapTranscriptPosToGenomic(user_seq_gtf, id, start, end)\n",
    "                userCDSStartEndMap[id] = str(g_start)+\"|\"+str(g_end)\n",
    "        else:\n",
    "            canIdSeqMap[id] = seq.sequence_as_string()[1:]\n",
    "            g_start, g_end = mapTranscriptPosToGenomic(user_seq_gtf, id, start, end)\n",
    "            userCDSStartEndMap[id] = str(g_start)+\"|\"+str(g_end)\n",
    "        \n",
    "del user_seq_gtf\n",
    "#-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing blast result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'999973|999059'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptGeneMap['All-NR_024540']\n",
    "\n",
    "refCDSStartEndMap['NM_021170']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "if options.out:\n",
    "    ofs = open(options.out,\"w\", encoding='utf-8')\n",
    "else:\n",
    "    ofs = sys.stdout\n",
    "    \n",
    "def errInfo(err, id, seq, transcript, refSeq, similarity, seqLength, refSeqLength, \n",
    "            len_diff, upstreamSimilarity, u_similar_res, downstreamSimilarity, d_similar_res, stopCodonStateOneRound):\n",
    "    sys.stderr.write(err)\n",
    "    sys.stderr.write(id+\": \"+ seq +\"\\n\")\n",
    "    sys.stderr.write(transcript+\": \"+ refSeq +\"\\n\")\n",
    "    sys.stderr.write(\"Similarity: \"+ str(similarity) +\"\\n\")  \n",
    "    sys.stderr.write(\"Candidate length: \"+ str(seqLength) +\"\\n\")  \n",
    "    sys.stderr.write(\"Reference length: \"+ str(refSeqLength) +\"\\n\")  \n",
    "    sys.stderr.write(\"Length different: \"+ str(len_diff) +\"\\n\")  \n",
    "    sys.stderr.write(\"Upstream similarity (10aAA), similarity: \"+ str(upstreamSimilarity) +\"\\n\")  \n",
    "    sys.stderr.write(u_similar_res +\"\\n\")  \n",
    "    sys.stderr.write(\"Downstream similarity (20aAA), similarity: \"+ str(downstreamSimilarity) +\"\\n\")  \n",
    "    sys.stderr.write(d_similar_res +\"\\n\")  \n",
    "    sys.stderr.write(\"Stop codon status \"+stopCodonStateOneRound+'\\n')\n",
    "    sys.stderr.write(\"Unknown condition, please check ----- \\n\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "ofs.write(\"\\t\".join([\"Gene\", \"Isoform\", \"CDS Start\", \"CDS End\", \"Class\", \n",
    "                     \"Protein Length\" ,\"Frame\", \"Start Codon\",\"Stop Codon\", \"Reference\",\"Protein Length Change\",\"Predicted Protein Sequence\"])+'\\n')\n",
    "\n",
    "frameMap = { 'unchanged': 1,\n",
    "             \"5' elongation\": 2,\n",
    "             \"3' elongation\": 2,\n",
    "             \"insert\": 2,\n",
    "             \"delete\": 2,\n",
    "             \"contain known orf\": 2,\n",
    "             'in-frame change': 3,\n",
    "             'frameshift': 4,\n",
    "             'novel start': 5,\n",
    "             'novel transcript': 5,\n",
    "             'novel': 5 ,\n",
    "             'no reference orf': 5,\n",
    "             'todo1': 0 ,\n",
    "             'todo2': 0 ,\n",
    "             'todo3': 0}\n",
    "classMap ={ 0: \"todo\", 1: \"unchanged\", 2:\"elongation\", 3:\"in-frame change\", 4:\"frameshift\", 5:\"novel\"}\n",
    "\n",
    "# impact priority: unchanged < elongation < inframe < frameshift < novel <- ''\n",
    "\n",
    "for id, seq in canIdSeqMap.items():\n",
    "    gene = '' #得到基因\n",
    "    \n",
    "    if not id in transcriptGeneMap.keys():\n",
    "        continue # 不在关注的基因内\n",
    "    \n",
    "    if (\"-N\" in id):  # 如果是参考的话，则不考虑\n",
    "        gene = transcriptGeneMap[id]\n",
    "        nm = id.replace(\"All-\",\"\")\n",
    "        if nm.startswith(\"NR\") or not nm in refCDSStartEndMap.keys():\n",
    "            ofs.write(\"\\t\".join([gene, id, '', '', \"known\", \"\", \"known\", \"known\", \"\", \"\"])+\"\\n\")\n",
    "            continue\n",
    "        nm_s_e = refCDSStartEndMap[nm]\n",
    "        nm_s_e = nm_s_e.split(\"|\")\n",
    "        ofs.write(\"\\t\".join([gene, id, nm_s_e[0], nm_s_e[1], \"known\", str(len(refIdSeqMap[nm])), \"known\", \"known\", \"\", \"\"])+\"\\n\")\n",
    "        continue     # 如果是参考的话，则不考虑\n",
    "    \n",
    "    user_transcript_start = int(userCDSStartEndMap[id].split(\"|\")[0])\n",
    "    user_transcript_end   = int(userCDSStartEndMap[id].split(\"|\")[1])\n",
    "\n",
    "    gene = transcriptGeneMap[id] #得到基因\n",
    "    \n",
    "    \n",
    "    transcript_in_gene = geneTranscriptListMap[gene] # 得到基因内的转录本\n",
    "    transcript_in_gene = [t for t in transcript_in_gene if not t.startswith(\"A\")] # 只考虑参考转录本，不以ALL-开头\n",
    "    \n",
    "    \n",
    "    frameshiftStateFinal = []       # 单个基因\n",
    "    frameshiftTranscriptFinal = []  # 单个基因\n",
    "    stopCodonStateFinal = []       # 单个基因\n",
    "    lengthChangeFinal = []\n",
    "    startCodonStateFinal = []\n",
    "    \n",
    "    #sys.stderr.write(id,str(user_transcript_start),str(user_transcript_end))\n",
    "    seqLength    = len(seq) #待研究的转录本信息\n",
    "    strand = ''\n",
    "    if user_transcript_start - user_transcript_end > 0:\n",
    "        strand = '+'\n",
    "    elif user_transcript_start - user_transcript_end < 0:\n",
    "        strand = '-'\n",
    "    maximum_similiary = 0\n",
    "      \n",
    "    for transcript in transcript_in_gene: # 遍历基因内的参考转录本\n",
    "        \n",
    "        frameshiftStateOneRound = '' # 单个transcript\n",
    "        stopCodonStateOneRound = ''  # 单个transcript\n",
    "        startCodonStateOneRound = ''\n",
    "        \n",
    "        if not transcript in refIdSeqMap.keys():\n",
    "            continue # 如果没有氨基酸序列，则continue\n",
    "        refSeq = refIdSeqMap[transcript]\n",
    "        \n",
    "        refSeqLength = len(refSeq) # 参考转录本信息\n",
    "        similarity, s_similar_res = proteinSimilarity(seq, refSeq)\n",
    "        upstreamSimilarity, u_similar_res = proteinSimilarity(seq[0:10], refSeq[0:10]) # 前十个氨基酸序列的相似性\n",
    "        downstreamSimilarity, d_similar_res = proteinSimilarity(seq[-20:], refSeq[-20:]) # 后二十个氨基酸序列的相似性\n",
    "        if similarity > maximum_similiary:\n",
    "            maximum_similiary = similarity\n",
    "        \n",
    "\n",
    "        pos_split = refCDSStartEndMap[transcript].split(\"|\")\n",
    "        if pos_split[1] == '': continue\n",
    "        ref_start = int(pos_split[0])\n",
    "        ref_end = int(pos_split[1])\n",
    "              \n",
    "        # 判断终止密码子的位置 stopCodon\n",
    "        if user_transcript_end == ref_end:\n",
    "            stopCodonStateOneRound = \"unchanged\"\n",
    "        elif strand == '+':\n",
    "            if user_transcript_end > ref_end:\n",
    "                stopCodonStateOneRound = \"late\"\n",
    "            else:\n",
    "                stopCodonStateOneRound = \"early\"\n",
    "        elif strand == \"-\":\n",
    "            if user_transcript_end > ref_end:\n",
    "                stopCodonStateOneRound = \"early\"\n",
    "            else:\n",
    "                stopCodonStateOneRound = \"late\" \n",
    "                \n",
    "        # 判断起始密码子的位置\n",
    "        if user_transcript_start == ref_start:\n",
    "            startCodonStateOneRound = \"unchanged\"\n",
    "        elif strand == '+':\n",
    "            if user_transcript_start > ref_start:\n",
    "                startCodonStateOneRound = \"late\"\n",
    "            else:\n",
    "                startCodonStateOneRound = \"early\"\n",
    "        elif strand == \"-\":\n",
    "            if user_transcript_start > ref_start:\n",
    "                startCodonStateOneRound = \"early\"\n",
    "            else:\n",
    "                startCodonStateOneRound = \"late\"        \n",
    "        \n",
    "\n",
    "                \n",
    "        # 判断移码情况 frameshift\n",
    "        len_diff = seqLength - refSeqLength   \n",
    "        if user_transcript_start == ref_start and user_transcript_end == ref_end :\n",
    "            if seq == refSeq:\n",
    "                frameshiftStateOneRound = \"unchanged\"\n",
    "            elif similarity >= 95 and (upstreamSimilarity!=100 or downstreamSimilarity!=100):\n",
    "                frameshiftStateOneRound = \"in-frame change\" # 相似性高的，归为in-frame\n",
    "            elif downstreamSimilarity >= 90 and (seq[0:5] in refSeq or refSeq[0:5] in seq or upstreamSimilarity >= 90):\n",
    "                frameshiftStateOneRound = \"in-frame change\" # 相似性高，且前面相同\n",
    "            elif downstreamSimilarity <= 50 and (seq[0:5] in refSeq or refSeq[0:5] in seq or upstreamSimilarity >= 90):\n",
    "                frameshiftStateOneRound = \"frameshift\"  # 前面一致，后面不一致\n",
    "            elif downstreamSimilarity >= 50 and seq[-1] == refSeq[-1] and upstreamSimilarity >= 90 and similarity >= 90:\n",
    "                frameshiftStateOneRound = \"in-frame change\" # 前面不一致，后面最后一个碱基，且后面有几个碱基一致\n",
    "            elif downstreamSimilarity >= 90 and (not seq[0:5] in refSeq and not refSeq[0:5] in seq):\n",
    "                frameshiftStateOneRound = \"novel transcript\" # 虽然后半部分相同，但前面不同\n",
    "            elif downstreamSimilarity <= 50 and upstreamSimilarity <= 50 and (similarity <= 50 or (similarity > 80  and abs(len_diff)) > 200 ) :\n",
    "                frameshiftStateOneRound = \"novel transcript\" # 前后都不同，且相似性低\n",
    "            else:\n",
    "                errInfo(\"Same start and end codon, but different sequences\\n\", id, seq, transcript, refSeq, similarity, seqLength, refSeqLength, \n",
    "                                    len_diff, upstreamSimilarity, u_similar_res, downstreamSimilarity, d_similar_res, stopCodonStateOneRound)\n",
    "        elif (seq[0:5] in refSeq or refSeq[0:5] in seq) and (seq[-5:] in refSeq or refSeq[-5:] in seq):\n",
    "            frameshiftStateOneRound = \"in-frame change\"\n",
    "        elif user_transcript_start == ref_start and user_transcript_end != ref_end:\n",
    "            if stopCodonStateOneRound == \"late\":\n",
    "                if refSeq[-5:] in seq or upstreamSimilarity >= 90:\n",
    "                    frameshiftStateOneRound = \"in-frame change\"\n",
    "                else:\n",
    "                    frameshiftStateOneRound = \"frameshift\"\n",
    "            elif stopCodonStateOneRound == \"early\":\n",
    "                if seq[-5:] in refSeq or upstreamSimilarity >= 90:\n",
    "                    frameshiftStateOneRound = \"in-frame change\"\n",
    "                else:\n",
    "                    frameshiftStateOneRound = \"frameshift\"\n",
    "            else:\n",
    "                errInfo(\"Same start, different end\\n\", id, seq, transcript, refSeq, similarity, seqLength, refSeqLength, \n",
    "                                    len_diff, upstreamSimilarity, u_similar_res, downstreamSimilarity, d_similar_res, stopCodonStateOneRound)\n",
    "        elif user_transcript_start != ref_start and user_transcript_end == ref_end:\n",
    "            frameshiftStateOneRound = \"novel start\"\n",
    "        elif user_transcript_start != ref_start and user_transcript_end != ref_end:\n",
    "            frameshiftStateOneRound = \"novel transcript\"        \n",
    "        else:\n",
    "            frameshiftStateOneRound = \"todo1\"\n",
    "            errInfo(\"todo1\\n\", id, seq, transcript, refSeq, similarity, seqLength, refSeqLength, \n",
    "                                    len_diff, upstreamSimilarity, u_similar_res, downstreamSimilarity, d_similar_res, stopCodonStateOneRound)\n",
    "   \n",
    "\n",
    "    # update\n",
    "        frameshiftStateFinal.append(frameshiftStateOneRound)\n",
    "        frameshiftTranscriptFinal.append(transcript)\n",
    "        stopCodonStateFinal.append(stopCodonStateOneRound)\n",
    "        lengthChangeFinal.append(str(len_diff))\n",
    "        startCodonStateFinal.append(startCodonStateOneRound)\n",
    "    ############# write output\n",
    "    #print(frameshiftStateFinal)\n",
    "    #print(frameshiftTranscriptFinal)\n",
    "    #print(stopCondanStateFinal)\n",
    "\n",
    "    if (len(stopCodonStateFinal)==0):\n",
    "        frameshiftStateFinal = [\"no reference orf\"]\n",
    "       \n",
    "    ofs.flush()\n",
    "    \n",
    "    ofs.write(gene+'\\t')\n",
    "    ofs.write(id+'\\t')    \n",
    "    ofs.write(str(user_transcript_start)+'\\t')       \n",
    "    ofs.write(str(user_transcript_end)+'\\t')  \n",
    "    ofs.write(classMap[min([frameMap[t] for t in frameshiftStateFinal])]+'\\t')\n",
    "    ofs.write(str( len(seq)+1)+'\\t')    \n",
    "    ofs.write(', '.join(frameshiftStateFinal)+'\\t')\n",
    "    ofs.write(', '.join(startCodonStateFinal)+'\\t')\n",
    "    ofs.write(', '.join(stopCodonStateFinal)+'\\t')\n",
    "    ofs.write(', '.join(frameshiftTranscriptFinal)+'\\t')\n",
    "    ofs.write(', '.join(lengthChangeFinal)+'\\t')\n",
    "    ofs.write('M'+seq+'\\n')    \n",
    "      \n",
    "\n",
    "ofs.flush()    \n",
    "ofs.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.489px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
