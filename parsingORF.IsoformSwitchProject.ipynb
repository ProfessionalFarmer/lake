{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gtfParser Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#######################################################################################\n",
    "###                                                                                 ###\n",
    "###     Copyright (C) 2019  Zhongxu ZHU, CityU, 20200925                            ###\n",
    "#######################################################################################\n",
    "\n",
    "# https://github.com/Jverma/GFF-Parser\n",
    "\n",
    "\n",
    "class gtfParser:\n",
    "    def __init__(self, input_file):\n",
    "        import sys\n",
    "        self.data = {}\n",
    "        self.dict = {}\n",
    "        self.gene_attributes_dict = {} # ZZX\n",
    "        self.transcriptID_geneID_dict = {} # ZZX\n",
    "\n",
    "        sys.stderr.write(\"#####################\\nParsing reference gtf file: \" + input_file + '\\n#####################\\n')\n",
    "\n",
    "        for line in open(input_file):\n",
    "            if line.startswith(\"#\"): continue\n",
    "            record = line.strip().split(\"\\t\")\n",
    "            sequence_name = record[0]\n",
    "            source = record[1]\n",
    "            feature = record[2]\n",
    "            start = int(record[3])\n",
    "            end = int(record[4])\n",
    "            if (record[5] != '.'):\n",
    "                score = record[5]\n",
    "            else:\n",
    "                score = None\n",
    "            strand = record[6]\n",
    "            if (record[7] != '.'):\n",
    "                frame = record[7]\n",
    "            else:\n",
    "                frame = None\n",
    "            \n",
    "            attributes = record[8].split(';')\n",
    "            attributes = [x.strip() for x in attributes[0:-1]] # ZZX\n",
    "            \n",
    "            if(\" \" in record[8] and \"\\\"\" in record[8]): # compatible with refSeq annotation 20210505\n",
    "                attributes = {x.split(' ')[0]: x.split(' ')[1].strip(\"\\\"\") for x in attributes if \" \" in x} # ZZX\n",
    "            elif (\"=\" in record[8]) : # compatible with gencode annotation 20210505\n",
    "                attributes = {x.split('=')[0]: x.split('=')[1] for x in attributes} # ZZX\n",
    "                           \n",
    "            if not (sequence_name in self.data): self.data[sequence_name] = []\n",
    "            alpha = {'source': source, 'feature': feature, 'start': start, 'end': end, 'score': score, 'strand': strand,\n",
    "                     'frame': frame}\n",
    "            # python 3 .items(), python 2 .iteritems() ZZX\n",
    "            for k, v in attributes.items(): alpha[k] = v\n",
    "            self.data[sequence_name].append(alpha)\n",
    "\n",
    "        # ZZX\n",
    "        for k, v in self.data.items():\n",
    "            for alpha in v:\n",
    "                \n",
    "                if alpha['feature'] == 'gene': continue # compatible with refSeq annotation 20210505\n",
    "                \n",
    "                gene_id = alpha[\"gene_id\"] # refSeq version\n",
    "                gene_id = alpha[\"gene_name\"] # gencode version,如果是refseq，注释掉该行\n",
    "                transcript_id = alpha[\"transcript_id\"]\n",
    "\n",
    "                self.transcriptID_geneID_dict[transcript_id] = gene_id\n",
    "                if gene_id in self.gene_attributes_dict.keys():\n",
    "                    self.gene_attributes_dict[gene_id].append(alpha)\n",
    "                else:\n",
    "                    self.gene_attributes_dict[gene_id] = list()\n",
    "                    self.gene_attributes_dict[gene_id].append(alpha)\n",
    "\n",
    "\n",
    "    def getRecordsByID(self, id, attType, attValue):\n",
    "        \"\"\" Gets all the features for a given gene.\n",
    "            Parameters\n",
    "            ----------\n",
    "            id : Identifier of the gene (gene_id) or mRNA (transcript_id).\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            A list of dictionaries where each dictionary contains the\n",
    "            informations about features for the transcript.\n",
    "            \"\"\"\n",
    "\n",
    "        att_list = []\n",
    "        if id in self.gene_attributes_dict.keys():\n",
    "            for x in self.gene_attributes_dict[id]:\n",
    "                if ( attType in x.keys() and  x[attType] == attValue ):\n",
    "                    att_info = x\n",
    "                    att_list.append(att_info)\n",
    "        elif id in self.transcriptID_geneID_dict.keys():\n",
    "            for x in self.gene_attributes_dict[self.transcriptID_geneID_dict[id]]:\n",
    "                if ( attType in x.keys() and  x[attType] == attValue and x[\"transcript_id\"] == id):\n",
    "                    att_info = x\n",
    "                    att_list.append(att_info)\n",
    "        else:\n",
    "            sys.stderr.write(\"Could not find ID \"+id+'\\n')\n",
    "            sys.stderr.write(\"Could not find attribute \" + attType + \": \" + attValue+'\\n')\n",
    "            sys.exit(1)\n",
    "\n",
    "        return att_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "import fastaparser   \n",
    "\n",
    "\"\"\"\n",
    "Description\n",
    "\"\"\"\n",
    "__author__    = \"Zhongxu\"\n",
    "__copyright__ = \"Copyright 2020, Planet Earth\"\n",
    "\n",
    "sys.argv = [\"\", \"-c\", \"/data/home2/Zhongxu/tmp/ORFFinder/CRC20230310Full/ensembl/candidate.aa.fa\",\n",
    "                \"-r\", \"/data/home2/Zhongxu/tmp/ORFFinder/CRC20230310Full/ensembl/ref.aa.fa\",\n",
    "                \"-m\", \"/data/home2/Zhongxu/tmp/ORFFinder/CRC20230310Full/ensembl/transcript.gene.map\",\n",
    "                \"-o\", \"/data/home2/Zhongxu/tmp/ORFFinder/CRC20230310Full/ensembl/orf.analysis.tsv\",\n",
    "                \"-p\", \"orffinder\", # sqanti or orffinder\n",
    "                #\"-g\", \"/data/home2/Zhongxu/Ref/refSeq.hg38.gtf\",\n",
    "                \"-g\", \"/data/home2/Zhongxu/tmp/ORFFinder/gencode.v37.annotation.gff3\",\n",
    "                #\"-g\", \"/data/home2/Zhongxu/ref/refSeq.hg19.gtf\",\n",
    "                \"-s\", \"/data/home2/Zhongxu/work/cuhk-crc/20230310out/gencode/1mergegff/all.5.filter.gtf\",\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/cuhk-crc/20230310out/refseq/1mergegff/all.3.filter20230311.ThreeClassCode.gtf\",\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/cuhk-crc/20220507/gencode/1mergegff/all.5.filter.gtf\",\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/cuhk-crc/20220507/refseq/1mergegff/all.3.filter20220507.ThreeClassCode.gtf\"\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/cuhk-crc/analysis/t0504.ThreeClassCode.gtf\"\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/pbFLNC/c99i95refMin2/gff/s2.clean.gtf\"\n",
    "                #\"-s\", \"/dataserver145/genomics/zhongxu/work/HCC-organoid-AS/analysis0504gencode/organoid/1prepareMergedGff/all.5.filter.gtf\"\n",
    "                #\"-s\", \"/data/home2/Zhongxu/work/cuhk-crc/20210504Gencode/1prepareMergedGff/all.5.filter.gtf\"\n",
    "            \n",
    "           ]\n",
    "\n",
    "parser = OptionParser()\n",
    "parser.add_option(\"-c\", \"--candidate\", dest=\"candidate\",\n",
    "                  help=\"candidate protein sequence predicted by ORFFinder or Sqanti\", metavar=\"FILE\")\n",
    "parser.add_option(\"-r\", \"--reference\", dest=\"reference\",\n",
    "                  help=\"reference protein sequence\", metavar=\"FILE\")\n",
    "parser.add_option(\"-m\", \"--map\", dest=\"idmap\",\n",
    "                  help=\"1st col: transcript ID, 2ed col: Gene ID\", metavar=\"FILE\")\n",
    "parser.add_option(\"-o\", \"--output\", dest=\"out\",\n",
    "                  help=\"Output file path\", metavar=\"FILE\")\n",
    "parser.add_option(\"-g\", \"--refgtf\", dest=\"refgtf\",\n",
    "                  help=\"GTF file path\", metavar=\"FILE\")\n",
    "parser.add_option(\"-s\", \"--usergtf\", dest=\"usergtf\",\n",
    "                  help=\"GTF file path\", metavar=\"FILE\")\n",
    "parser.add_option(\"-b\", \"--blast\", dest=\"blast\",\n",
    "                  help=\"Blast file path\", metavar=\"FILE\")\n",
    "parser.add_option(\"-p\", \"--predict\", dest=\"orfpredictiontool\",\n",
    "                  help=\"ORF prediction tool. sqanti or orffinder\", metavar=\"FILE\")\n",
    "parser.add_option(\"-e\", \"--ensembl\", dest=\"ensemblannotation\",action=\"store_true\", default=False,\n",
    "                  help=\"If ensembl or gencode annotation\", metavar=\"FILE\")\n",
    "#-----------------------------------------------------\n",
    "\n",
    "\n",
    "def proteinSimilarity(seq1,seq2):\n",
    "    from Bio import pairwise2 as pw2\n",
    "    seq_length = min(len(seq1), len(seq2))\n",
    "    global_align = pw2.align.globalxx(seq1, seq2)\n",
    "    try:\n",
    "        matches = global_align[0][2]\n",
    "    except Exception as e:\n",
    "        print(\"Seq1\\n\")\n",
    "        print(seq1)\n",
    "        print(\"\\nSeq2\\n\")\n",
    "        print(seq2)\n",
    "    percent_match = (matches / seq_length) * 100\n",
    "    seq2_res = global_align[0][0] + '\\n' + global_align[0][1]\n",
    "    return round( percent_match,1 ), seq2_res\n",
    "\n",
    "#-----------------------------------------------------\n",
    "(options, args) = parser.parse_args()\n",
    "#-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -- parsing this file to store gene and transcript mapping information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/home2/Zhongxu/tmp/ORFFinder/CRC20230310Full/ensembl/transcript.gene.map' mode='r' encoding='UTF-8'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "__main__:7: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/home2/Zhongxu/tmp/ORFFinder/CRC20230310Full/ensembl/transcript.gene.map' mode='r' encoding='UTF-8'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "#####################\n",
      "Parsing reference gtf file: /data/home2/Zhongxu/tmp/ORFFinder/gencode.v37.annotation.gff3\n",
      "#####################\n",
      "__main__:21: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/home2/Zhongxu/tmp/ORFFinder/gencode.v37.annotation.gff3' mode='r' encoding='UTF-8'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -- parsing ref protein sequence and store cds start and end\n",
      "3 -- parsing user protein sequence and store cds start and end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "Parsing reference gtf file: /data/home2/Zhongxu/work/cuhk-crc/20230310out/gencode/1mergegff/all.5.filter.gtf\n",
      "#####################\n",
      "__main__:21: ResourceWarning: unclosed file <_io.TextIOWrapper name='/data/home2/Zhongxu/work/cuhk-crc/20230310out/gencode/1mergegff/all.5.filter.gtf' mode='r' encoding='UTF-8'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -- parsing user protein sequence and store cds start and end - ORFFinder\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-----------------------------------------------------\n",
    "print(\"1 -- parsing this file to store gene and transcript mapping information\")\n",
    "# parsing this file to store gene and transcript mapping information\n",
    "transcriptGeneMap = {line.strip().split(\"\\t\")[0]:line.strip().split(\"\\t\")[1] for line in open(options.idmap)}\n",
    "geneTranscriptListMap = {}\n",
    "\n",
    "for line in open(options.idmap):\n",
    "    gene = line.strip().split(\"\\t\")[1]\n",
    "    transcript = line.strip().split(\"\\t\")[0]\n",
    "    if not gene in geneTranscriptListMap.keys():\n",
    "        geneTranscriptListMap[gene]=[]\n",
    "    geneTranscriptListMap[gene].append(transcript)\n",
    "        \n",
    "\n",
    "\n",
    "# store CDS start and end position\n",
    "refCDSStartEndMap = {}\n",
    "ref_seq_gtf = gtfParser(options.refgtf)\n",
    "\n",
    "\n",
    "print(\"2 -- parsing ref protein sequence and store cds start and end\")\n",
    "# ref.aa.fa: parsing ref protein sequence and store cds start and end\n",
    "refIdSeqMap = {}\n",
    "\n",
    "with open(options.reference) as fasta_file:\n",
    "    parser = fastaparser.Reader(fasta_file)\n",
    "    for seq in parser:\n",
    "        if seq.sequence_as_string() == \"SEQUENCE UNAVAILABLE\": continue\n",
    "        for e in seq.id.split(\";\"):\n",
    "            # obtain cds start and end\n",
    "            \n",
    "            refmRNA_start = ref_seq_gtf.getRecordsByID(e, \"feature\", \"start_codon\")\n",
    "            start = ''\n",
    "            end = ''\n",
    "                        \n",
    "            if len(refmRNA_start) != 1:\n",
    "                start = ''\n",
    "                end = ''\n",
    "            else:\n",
    "                strand = refmRNA_start[0][\"strand\"]\n",
    "                if strand == '+':                \n",
    "                    start = refmRNA_start[0][\"start\"]\n",
    "                else: # 如果在负链\n",
    "                    start = refmRNA_start[0][\"end\"]\n",
    "                \n",
    "                refmRNA_end = ref_seq_gtf.getRecordsByID(e, \"feature\", \"stop_codon\")\n",
    "                if (len(refmRNA_end) != 1):\n",
    "                    end = ''\n",
    "                else:\n",
    "                    if strand == '+':\n",
    "                        end = refmRNA_end[0][\"end\"]\n",
    "                    else:\n",
    "                        end = refmRNA_end[0][\"start\"]           \n",
    "            \n",
    "            refCDSStartEndMap[e] = str(start)+\"|\"+str(end)\n",
    "            # remove * at the end of sequence and remove the first M amino acid\n",
    "            if seq.sequence_as_string()[-1]=='*': # if the last AA is *\n",
    "                refIdSeqMap[e] = seq.sequence_as_string()[1:-1] \n",
    "            else: # if the last AA is not *\n",
    "                refIdSeqMap[e] = seq.sequence_as_string()\n",
    "del ref_seq_gtf\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------\n",
    "# 将candidate.aa.fa的结果读到map中，ORFID：line #结果是best的，一个orf只对应一行\n",
    "\n",
    "print(\"3 -- parsing user protein sequence and store cds start and end\")\n",
    "# parsing user protein sequence and store cds start and end\n",
    "user_seq_gtf = gtfParser(options.usergtf)\n",
    "userCDSStartEndMap = {}\n",
    "\n",
    "\n",
    "\n",
    "# parsing predicted ORF and store cds start and end\n",
    "canIdSeqMap = {}\n",
    "def mapTranscriptPosToGenomic(gtf, transcriptID, start, end):\n",
    "    records = gtf.getRecordsByID(transcriptID, \"feature\", \"exon\")\n",
    "    strand = records[0][\"strand\"]\n",
    "    \n",
    "    regions = []\n",
    "    \n",
    "    for record in records:\n",
    "        e_start = record[\"start\"]\n",
    "        e_end   = record[\"end\"]\n",
    "        regions.extend(list(range(e_start,e_end+1)))\n",
    "    \n",
    "    if strand == '+':\n",
    "        start = regions[int(start)] # 本来打算要start-1的，不知道为什么不减1得到的是正确的。20210421补充，sqanti是正确的\n",
    "        end   = regions[int(end)]\n",
    "    else:\n",
    "        start = regions[-1*int(start)-1] # 本来打算start，不知道为什么必须减1得到的是正确的\n",
    "        end   = regions[-1*int(end)-1]\n",
    "    return start, end\n",
    "\n",
    "\n",
    "\n",
    "if(options.orfpredictiontool==\"orffinder\"): # 如果是ORFFinder输出的fasta\n",
    "    print(\"3 -- parsing user protein sequence and store cds start and end - ORFFinder\")              \n",
    "    with open(options.candidate) as fasta_file:\n",
    "        parser = fastaparser.Reader(fasta_file)\n",
    "\n",
    "        for seq in parser:\n",
    "            \n",
    "            if('-CDS:' in seq.id):\n",
    "                id = seq.id.split(\"_\",1)[1].split(\":\")[0] + \":\" + seq.id.split(\"_\",1)[1].split(\":\")[1]\n",
    "                start = seq.id.split(\":\")[2]\n",
    "                end = seq.id.split(\":\")[3].split(\" \")[0]\n",
    "            else:\n",
    "                id = seq.id.split(\"_\",1)[1].split(\":\")[0]\n",
    "                start = seq.id.split(\":\")[1]\n",
    "                end = seq.id.split(\":\")[2].split(\" \")[0]\n",
    "            orf = id+\":\"+start+\":\"+end\n",
    "            # >lcl|ORF2_All-H720T_ORG.7684.1:140:1894 unnamed protein product\n",
    "            if id in canIdSeqMap.keys(): # 选择最长的那个\n",
    "                if ( (len(seq.sequence_as_string()) -1 ) > len(canIdSeqMap[id]) ): # 减1是不考虑第一个M氨基酸\n",
    "                    canIdSeqMap[id] = seq.sequence_as_string()[1:]\n",
    "                    g_start, g_end = mapTranscriptPosToGenomic(user_seq_gtf, id, start, end)\n",
    "                    userCDSStartEndMap[id] = str(g_start)+\"|\"+str(g_end)\n",
    "            else:\n",
    "                canIdSeqMap[id] = seq.sequence_as_string()[1:]\n",
    "                g_start, g_end = mapTranscriptPosToGenomic(user_seq_gtf, id, start, end)\n",
    "                userCDSStartEndMap[id] = str(g_start)+\"|\"+str(g_end)\n",
    "elif(options.orfpredictiontool==\"sqanti\"):\n",
    "    print(\"3 -- parsing user protein sequence and store cds start and end - SQANTI\") \n",
    "    with open(options.candidate) as fasta_file:\n",
    "        parser = fastaparser.Reader(fasta_file)\n",
    "        \n",
    "        for seq in parser:\n",
    "            # >All-H720T_ORG.7684.1   gene_41230|GeneMark.hmm|584_aa|+|141|1895\n",
    "            id = seq.id\n",
    "            start = str(int(seq.description.split(\"|\")[4])-1)\n",
    "            end = str(int(seq.description.split(\"|\")[5])-1)\n",
    "\n",
    "            orf = id+\":\"+start+\":\"+end\n",
    "\n",
    "            canIdSeqMap[id] = seq.sequence_as_string()[1:]\n",
    "            g_start, g_end = mapTranscriptPosToGenomic(user_seq_gtf, id, start, end)\n",
    "            userCDSStartEndMap[id] = str(g_start)+\"|\"+str(g_end)                \n",
    "            \n",
    "            \n",
    "del user_seq_gtf\n",
    "\n",
    "#-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing blast result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#transcriptGeneMap['All-H720T_ORG.7684.1']\n",
    "\n",
    "#refCDSStartEndMap['All-H720T_ORG.7684.1']\n",
    "\n",
    "#print(refIdSeqMap['ENST00000532278.1']+'---')\n",
    "#print(len(canIdSeqMap.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------\n",
    "if options.out:\n",
    "    ofs = open(options.out,\"w\", encoding='utf-8')\n",
    "else:\n",
    "    ofs = sys.stdout\n",
    "    \n",
    "def errInfo(err, id, seq, transcript, refSeq, similarity, seqLength, refSeqLength, \n",
    "            len_diff, upstreamSimilarity, u_similar_res, downstreamSimilarity, d_similar_res, stopCodonStateOneRound):\n",
    "    sys.stderr.write(err)\n",
    "    sys.stderr.write(id+\": \"+ seq +\"\\n\")\n",
    "    sys.stderr.write(transcript+\": \"+ refSeq +\"\\n\")\n",
    "    sys.stderr.write(\"Similarity: \"+ str(similarity) +\"\\n\")  \n",
    "    sys.stderr.write(\"Candidate length: \"+ str(seqLength) +\"\\n\")  \n",
    "    sys.stderr.write(\"Reference length: \"+ str(refSeqLength) +\"\\n\")  \n",
    "    sys.stderr.write(\"Length different: \"+ str(len_diff) +\"\\n\")  \n",
    "    sys.stderr.write(\"Upstream similarity (10aAA), similarity: \"+ str(upstreamSimilarity) +\"\\n\")  \n",
    "    sys.stderr.write(u_similar_res +\"\\n\")  \n",
    "    sys.stderr.write(\"Downstream similarity (20aAA), similarity: \"+ str(downstreamSimilarity) +\"\\n\")  \n",
    "    sys.stderr.write(d_similar_res +\"\\n\")  \n",
    "    sys.stderr.write(\"Stop codon status \"+stopCodonStateOneRound+'\\n')\n",
    "    sys.stderr.write(\"Unknown condition, please check ----- \\n\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "ofs.write(\"\\t\".join([\"Gene\", \"Isoform\", \"CDS Start\", \"CDS End\", \"Class\", \n",
    "                     \"Protein Length\" ,\"Frame\", \"Start Codon\",\"Stop Codon\", \"Reference\",\"Protein Length Change\",\"Predicted Protein Sequence\"])+'\\n')\n",
    "\n",
    "frameMap = { 'unchanged': 1,\n",
    "             \"5' elongation\": 2,\n",
    "             \"3' elongation\": 2,\n",
    "             \"insert\": 2,\n",
    "             \"delete\": 2,\n",
    "             \"contain annotated orf\": 2,\n",
    "             'in-frame change': 3,\n",
    "             'frameshift': 4,\n",
    "             'novel start': 5,\n",
    "             'novel transcript': 5,\n",
    "             'novel': 5 ,\n",
    "             'no reference orf': 6,\n",
    "             'todo1': 0 ,\n",
    "             'todo2': 0 ,\n",
    "             'todo3': 0}\n",
    "classMap ={ 0: \"todo\", 1: \"unchanged\", 2:\"elongation\", 3:\"in-frame change\", 4:\"frameshift\", 5:\"novel\", 6:\"non-coding or located in non-coding gene\"}\n",
    "\n",
    "# impact priority: unchanged < elongation < inframe < frameshift < novel <- ''\n",
    "\n",
    "n_trans = 0\n",
    "for id, seq in canIdSeqMap.items():\n",
    "    gene = '' #得到基因\n",
    "    n_trans = n_trans + 1\n",
    "    # if n_trans < 47015: continue  # debug  \n",
    "        \n",
    "    if not id in transcriptGeneMap.keys():\n",
    "        continue # 不在关注的基因内\n",
    "        \n",
    "    if ( \"-NM\" in id or \"-XM\" in id or \"-NR\" in id or \"-XR\" in id or \"ENST00\" in id):  # 如果是参考的话，则不考虑\n",
    "        gene = transcriptGeneMap[id]\n",
    "        nm = id.replace(\"All-\",\"\").replace(\"ALL-\",\"\")\n",
    "        if nm.startswith(\"NR\") or nm.startswith(\"XR\") or not nm in refCDSStartEndMap.keys():\n",
    "            ofs.write(\"\\t\".join([gene, id, '', '', \"annotated\", \"\", \"annotated\", \"annotated\", \"\", \"\"])+\"\\n\")\n",
    "            continue\n",
    "        if nm in refCDSStartEndMap.keys():# 如果在参考转录本的蛋白序列文件中candidate.aa.fa\n",
    "            nm_s_e = refCDSStartEndMap[nm]\n",
    "            nm_s_e = nm_s_e.split(\"|\")\n",
    "            pro_len = str(len(refIdSeqMap[nm]))\n",
    "        else: # 如果不在参考转录本的蛋白序列文件中candidate.aa.fa\n",
    "            nm_s_e = [' ', ' ']\n",
    "            pro_len = '0'\n",
    "            \n",
    "        ofs.write(\"\\t\".join([gene, id, nm_s_e[0], nm_s_e[1], \"annotated\", pro_len, \"annotated\", \"annotated\", \"\", \"\"])+\"\\n\")\n",
    "        continue     # 如果是参考的话，则不考虑\n",
    "    \n",
    "    if seq == \"\": # 如果预测的序列为空的话, sqanti会输出为空的序列\n",
    "        gene = transcriptGeneMap[id]\n",
    "        ofs.write(\"\\t\".join([gene, id, '', '', \"unannotated\", \"\", \"unannotated\", \"unannotated\", \"\", \"\"])+\"\\n\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    user_transcript_start = int(userCDSStartEndMap[id].split(\"|\")[0])\n",
    "    user_transcript_end   = int(userCDSStartEndMap[id].split(\"|\")[1])\n",
    "\n",
    "    gene = transcriptGeneMap[id] #得到基因\n",
    "    \n",
    "    \n",
    "    transcript_in_gene = geneTranscriptListMap[gene] # 得到基因内的转录本\n",
    "    transcript_in_gene = [t for t in transcript_in_gene if not t.startswith(\"A\")] # 只考虑参考转录本，不以ALL-开头\n",
    "    \n",
    "    \n",
    "    frameshiftStateFinal = []       # 单个基因\n",
    "    frameshiftTranscriptFinal = []  # 单个基因\n",
    "    stopCodonStateFinal = []       # 单个基因\n",
    "    lengthChangeFinal = []\n",
    "    startCodonStateFinal = []\n",
    "    \n",
    "    #sys.stderr.write(id,str(user_transcript_start),str(user_transcript_end))\n",
    "    seqLength    = len(seq) #待研究的转录本信息\n",
    "    strand = ''\n",
    "    if user_transcript_start - user_transcript_end < 0: # bug解决，原来是大于0，应该是小于，20210416\n",
    "        strand = '+'\n",
    "    elif user_transcript_start - user_transcript_end > 0:\n",
    "        strand = '-'\n",
    "    maximum_similiary = 0\n",
    "      \n",
    "    for transcript in transcript_in_gene: # 遍历基因内的参考转录本\n",
    "        # print(transcript) # debug\n",
    "        \n",
    "        frameshiftStateOneRound = '' # 单个transcript\n",
    "        stopCodonStateOneRound = ''  # 单个transcript\n",
    "        startCodonStateOneRound = ''\n",
    "        \n",
    "        if not transcript in refIdSeqMap.keys():\n",
    "            continue # 如果没有氨基酸序列，则continue\n",
    "        refSeq = refIdSeqMap[transcript]\n",
    "        \n",
    "        refSeqLength = len(refSeq) # 参考转录本信息    \n",
    "        if(refSeqLength) <= 2: continue # ENST00000679073.1的氨基酸序列是F* # 20230328\n",
    "        \n",
    "        similarity, s_similar_res = proteinSimilarity(seq, refSeq)\n",
    "                \n",
    "        upstreamSimilarity, u_similar_res = proteinSimilarity(seq[0:10], refSeq[0:10]) # 前十个氨基酸序列的相似性\n",
    "        downstreamSimilarity, d_similar_res = proteinSimilarity(seq[-20:], refSeq[-20:]) # 后二十个氨基酸序列的相似性\n",
    "        if similarity > maximum_similiary:\n",
    "            maximum_similiary = similarity\n",
    "        \n",
    "\n",
    "        pos_split = refCDSStartEndMap[transcript].split(\"|\")\n",
    "        if pos_split[1] == '': continue\n",
    "        ref_start = int(pos_split[0])\n",
    "        ref_end = int(pos_split[1])\n",
    "              \n",
    "        # 判断终止密码子的位置 stopCodon\n",
    "        if user_transcript_end == ref_end:\n",
    "            stopCodonStateOneRound = \"unchanged\"\n",
    "        elif strand == '+':\n",
    "            if user_transcript_end > ref_end:\n",
    "                stopCodonStateOneRound = \"late\"\n",
    "            else:\n",
    "                stopCodonStateOneRound = \"early\"\n",
    "        elif strand == \"-\":\n",
    "            if user_transcript_end > ref_end:\n",
    "                stopCodonStateOneRound = \"early\"\n",
    "            else:\n",
    "                stopCodonStateOneRound = \"late\" \n",
    "                \n",
    "        # 判断起始密码子的位置\n",
    "        #print(strand)\n",
    "        #print(str(user_transcript_start)+'-'+str(ref_start) )\n",
    "        #print(str(user_transcript_end)+'-'+str(ref_end) )\n",
    "        \n",
    "        if user_transcript_start == ref_start:\n",
    "            startCodonStateOneRound = \"unchanged\"\n",
    "        elif strand == '+':\n",
    "            if user_transcript_start > ref_start:\n",
    "                startCodonStateOneRound = \"late\"\n",
    "            else:\n",
    "                startCodonStateOneRound = \"early\"\n",
    "        elif strand == \"-\":\n",
    "            if user_transcript_start > ref_start:\n",
    "                startCodonStateOneRound = \"early\"\n",
    "            else:\n",
    "                startCodonStateOneRound = \"late\"        \n",
    "        \n",
    "\n",
    "                \n",
    "        # 判断移码情况 frameshift\n",
    "        len_diff = seqLength - refSeqLength\n",
    "        # 20210421不考虑起始位置，只根据相似性来判断\n",
    "        if True:\n",
    " #       if user_transcript_start == ref_start and user_transcript_end == ref_end :\n",
    "            if seq == refSeq:\n",
    "                frameshiftStateOneRound = \"unchanged\"\n",
    "            elif similarity >= 99 and abs(len_diff) <= 5: # 起始位置相同，相似度在95以上，且长度不变,定为不变，20210421\n",
    "                frameshiftStateOneRound = \"unchanged\"\n",
    "            elif similarity >= 99 and abs(len_diff) > 5: # 起始位置相同，相似度在95以上，且长度不变,定为不变，20210421\n",
    "                frameshiftStateOneRound = \"in-frame change\" \n",
    "            elif (seq[1:7] in refSeq or upstreamSimilarity >= 80) and (seq[-7:-1] in refSeq or downstreamSimilarity >= 80):\n",
    "                frameshiftStateOneRound = \"in-frame change\" # 前后都包含,不考虑\n",
    "            elif upstreamSimilarity >= 80 and downstreamSimilarity >= 80:\n",
    "                frameshiftStateOneRound = \"in-frame change\"\n",
    "            elif similarity < 50 and upstreamSimilarity >=80:\n",
    "                frameshiftStateOneRound = \"frameshift\" # 起始位置相同，但整体相似性不高，判断为移码\n",
    "            elif refSeq in seq and refSeq[1:5] != seq[1:5]:\n",
    "                frameshiftStateOneRound = \"contain annotated orf\" # 前面相同，后面不同\n",
    "            elif (seq[1:7] in refSeq or upstreamSimilarity >= 80) and not seq[-7:-1] in refSeq and downstreamSimilarity < 80:\n",
    "                frameshiftStateOneRound = \"frameshift\" # 前面相同，后面不同\n",
    "            elif not seq[1:7] in refSeq and upstreamSimilarity < 80:\n",
    "                frameshiftStateOneRound = \"novel transcript\" # 前面不同             \n",
    "            else:\n",
    "                errInfo(\"Same start and end codon, but different sequences\\n\", id, seq, transcript, refSeq, similarity, seqLength, refSeqLength, \n",
    "                                    len_diff, upstreamSimilarity, u_similar_res, downstreamSimilarity, d_similar_res, stopCodonStateOneRound)     \n",
    "        else:\n",
    "            frameshiftStateOneRound = \"todo1\"\n",
    "            errInfo(\"todo1\\n\", id, seq, transcript, refSeq, similarity, seqLength, refSeqLength, \n",
    "                                    len_diff, upstreamSimilarity, u_similar_res, downstreamSimilarity, d_similar_res, stopCodonStateOneRound)\n",
    "   \n",
    "\n",
    "    # update\n",
    "        frameshiftStateFinal.append(frameshiftStateOneRound)\n",
    "        frameshiftTranscriptFinal.append(transcript)\n",
    "        stopCodonStateFinal.append(stopCodonStateOneRound)\n",
    "        lengthChangeFinal.append(str(len_diff))\n",
    "        startCodonStateFinal.append(startCodonStateOneRound)\n",
    "    ############# write output\n",
    "    #print(frameshiftStateFinal)\n",
    "    #print(frameshiftTranscriptFinal)\n",
    "    #print(stopCondanStateFinal)\n",
    "\n",
    "    if (len(stopCodonStateFinal)==0):\n",
    "        frameshiftStateFinal = [\"no reference orf\"]\n",
    "    else:\n",
    "        seq='M'+seq # 添加第一个氨基酸M\n",
    "    \n",
    "    ofs.flush()\n",
    "    \n",
    "    ofs.write(gene+'\\t')\n",
    "    ofs.write(id+'\\t')    \n",
    "    ofs.write(str(user_transcript_start)+'\\t')       \n",
    "    ofs.write(str(user_transcript_end)+'\\t')  \n",
    "    ofs.write(classMap[min([frameMap[t] for t in frameshiftStateFinal])]+'\\t')\n",
    "    ofs.write(str( len(seq)+1)+'\\t')    \n",
    "    ofs.write(', '.join(frameshiftStateFinal)+'\\t')\n",
    "    ofs.write(', '.join(startCodonStateFinal)+'\\t')\n",
    "    ofs.write(', '.join(stopCodonStateFinal)+'\\t')\n",
    "    ofs.write(', '.join(frameshiftTranscriptFinal)+'\\t')\n",
    "    ofs.write(', '.join(lengthChangeFinal)+'\\t')\n",
    "    ofs.write(seq+'\\n')    \n",
    "    ofs.flush() \n",
    "    \n",
    "    \n",
    "\n",
    "ofs.flush()    \n",
    "ofs.close()\n",
    "\n",
    "\n",
    "print(\"Finished\\nTotal transcript: \")\n",
    "print(n_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7276e9be6493f5bdecb07efaa387d7db41d863fe6f68077f752da0926e1bd6b9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.497px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
